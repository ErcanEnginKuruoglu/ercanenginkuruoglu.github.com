<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=UTF-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Neural Network Achitectures</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">TVDS Group</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="team.html">Team</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Neural Network Achitectures</h1>
<div id="subtitle">
</div>
</div>
<ul>
<li><p>Neural Networks are everywhere nowadays, being able to fit any arbitrary function in order to discern some truth about the 
underlying data. When designing a Neural Network, the choice of architecture is of utmost importance, since a network too large 
would result in a network unable to generalize to other data, and a network too small would be unable to accurately reflect the 
underlying data distribution.

</p>
</li>
<li><p>The typical way the architecture is chosen is via the architect's intuition based on their previous experience with various 
Neural Network architectures. However, this relies heavily on the user's experience, and so automated ways of determining the 
optimal architecture have recently come about. This emerging field of Auto-ML is critical in developing reliable systems that 
can find the underlying truth of the data. 

</p>
</li>
<li><p>Several research directions in this field involve the use of Genetic Algorithms and Particle Swarm Optimization to 
determine the parameters. In this lab, we seek to use Bayesian-based methods to systematically determine optimal 
Neural Network architectures, and do so in a method that guarantees a global optimum, while attempting to speed up the process 
of reaching this state.

</p>
</li>
<li><p>For applications of this research, by optimizing the networks in an automated fashion, it would be possible to create a Neural 
Network architecture from scratch with no prior knowledge about the underlying network and what size works best. It also allows 
us, by using Bayesian methods, to include the designer’s previous knowledge if they so choose. Secondly, it should shrink the 
size of some Neural Networks that may be too large and over-tuned for the problem at hand, and enlarge those that are too 
small, to optimize the resources available and specifically in the case of larger networks, not waste resources on 
extraneous calculations. 

</p>
</li>
</ul>
<table class="imgtable"><tr><td>
<img src="project/neural1.png" alt="alt text" width="375px" height="200px" />&nbsp;</td>
<td align="left"></td></tr></table>
<table class="imgtable"><tr><td>
<img src="project/neural2.png" alt="alt text" width="363px" height="220px" />&nbsp;</td>
<td align="left"></td></tr></table>
<p>



</p>
<div id="footer">
<div id="footer-text">
Page generated 2022-10-17 20:49:41 中国标准时间, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
